{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables for \"A natural hazard risk modelling approach to human displacement - frontiers & challenges\"\n",
    "\n",
    "In this notebook we create the tables and human displacement risk values featured in the manuscript titled \"A natural hazard risk modelling approach to human displacement - frontiers & challenges\" by Meiler et al., 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths (to be adjusted when running on different machines)\n",
    "results_path = '/Users/simonameiler/Documents/work/03_code/repos/global-displacement-risk/data/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplementary Table 2. Global average annual human displacement values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_future_changes_multiple_scenarios(input_files, baseline_year, baseline_scenario, future_years, future_scenarios, metric):\n",
    "    \"\"\"\n",
    "    Calculate and display baseline totals, future absolute values, and percentage changes with future scenarios/years as columns.\n",
    "    Includes a final row with totals across all hazards, where percentage changes are correctly calculated from total values.\n",
    "\n",
    "    Parameters:\n",
    "        input_files (list of str): List of file paths to the input CSV files.\n",
    "        baseline_year (int): The baseline year (e.g., 2020).\n",
    "        baseline_scenario (str): The baseline scenario (e.g., 'current').\n",
    "        future_years (list of int): List of future years to consider (e.g., [2050, 2100]).\n",
    "        future_scenarios (list of str): List of future scenarios to consider (e.g., ['optimistic', 'pessimistic']).\n",
    "        metric (str): The metric column to calculate changes (e.g., 'AAD').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A summary table with future scenarios/years as columns, showing baseline totals, absolute values, and percentage changes.\n",
    "    \"\"\"\n",
    "    results = []  # Store results for all hazards\n",
    "    totals = {}  # Store aggregated totals for the last row\n",
    "\n",
    "    # Initialize totals for aggregation\n",
    "    totals['Hazard'] = 'Total Across All Hazards'\n",
    "    totals['Baseline Total'] = 0  # To accumulate baseline totals\n",
    "    for future_year in future_years:\n",
    "        for future_scenario in future_scenarios:\n",
    "            abs_column_name = f\"{future_scenario}_{future_year}_Value\"\n",
    "            perc_column_name = f\"{future_scenario}_{future_year}_Change (%)\"\n",
    "            totals[abs_column_name] = 0  # Initialize for sum\n",
    "            totals[perc_column_name] = 0  # Placeholder for percentage change\n",
    "\n",
    "    for file_path in input_files:\n",
    "        try:\n",
    "            # Extract hazard name from the file name\n",
    "            hazard = file_path.split('/')[-1].split('_')[0]\n",
    "            \n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Filter for baseline data\n",
    "            baseline_data = df[(df['year'] == baseline_year) & (df['scenario'] == baseline_scenario)]\n",
    "            baseline_total = baseline_data[metric].sum()\n",
    "            \n",
    "            # Dictionary to store results for this hazard\n",
    "            hazard_results = {'Hazard': hazard, 'Baseline Total': baseline_total}\n",
    "            totals['Baseline Total'] += baseline_total  # Accumulate baseline total\n",
    "            \n",
    "            for future_year in future_years:\n",
    "                for future_scenario in future_scenarios:\n",
    "                    # Filter for the future data\n",
    "                    future_data = df[(df['year'] == future_year) & (df['scenario'] == future_scenario)]\n",
    "                    future_total = future_data[metric].sum()\n",
    "                    \n",
    "                    # Calculate percentage change\n",
    "                    if baseline_total > 0:\n",
    "                        percentage_change = ((future_total - baseline_total) / baseline_total) * 100\n",
    "                    else:\n",
    "                        percentage_change = np.nan  # Handle zero baseline total\n",
    "                    \n",
    "                    # Add results to the hazard_results dictionary\n",
    "                    abs_column_name = f\"{future_scenario}_{future_year}_Value\"\n",
    "                    perc_column_name = f\"{future_scenario}_{future_year}_Change (%)\"\n",
    "                    hazard_results[abs_column_name] = future_total\n",
    "                    hazard_results[perc_column_name] = percentage_change\n",
    "                    \n",
    "                    # Accumulate totals for absolute values\n",
    "                    totals[abs_column_name] += future_total\n",
    "\n",
    "            # Append the results for this hazard\n",
    "            results.append(hazard_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    # Recalculate percentage changes for totals based on absolute values\n",
    "    for future_year in future_years:\n",
    "        for future_scenario in future_scenarios:\n",
    "            abs_column_name = f\"{future_scenario}_{future_year}_Value\"\n",
    "            perc_column_name = f\"{future_scenario}_{future_year}_Change (%)\"\n",
    "            total_future_value = totals[abs_column_name]\n",
    "            total_baseline_value = totals['Baseline Total']\n",
    "            if total_baseline_value > 0:\n",
    "                totals[perc_column_name] = ((total_future_value - total_baseline_value) / total_baseline_value) * 100\n",
    "            else:\n",
    "                totals[perc_column_name] = np.nan  # Handle zero baseline total\n",
    "\n",
    "    # Append the totals row\n",
    "    results.append(totals)\n",
    "\n",
    "    # Create a summary DataFrame\n",
    "    summary_df = pd.DataFrame(results)\n",
    "\n",
    "    # Print the summary\n",
    "    print(summary_df)\n",
    "\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Hazard  Baseline Total  optimistic_2050_Value  \\\n",
      "0                        tc    1.688406e+05           6.897092e+05   \n",
      "1                        cf    1.025745e+07           1.124110e+07   \n",
      "2                        FL    1.541652e+07           0.000000e+00   \n",
      "3                   drought    4.324839e+06           1.324890e+07   \n",
      "4  Total Across All Hazards    3.016765e+07           2.517972e+07   \n",
      "\n",
      "   optimistic_2050_Change (%)  pessimistic_2050_Value  \\\n",
      "0                  308.497257            1.001257e+06   \n",
      "1                    9.589657            1.152129e+07   \n",
      "2                 -100.000000            0.000000e+00   \n",
      "3                  206.344442            1.400793e+07   \n",
      "4                  -16.534041            2.653048e+07   \n",
      "\n",
      "   pessimistic_2050_Change (%)  optimistic_2100_Value  \\\n",
      "0                   493.019059           9.878875e+05   \n",
      "1                    12.321172           1.426981e+07   \n",
      "2                  -100.000000           2.296271e+07   \n",
      "3                   223.894928           1.443440e+07   \n",
      "4                   -12.056524           5.265481e+07   \n",
      "\n",
      "   optimistic_2100_Change (%)  pessimistic_2100_Value  \\\n",
      "0                  485.100753            1.769823e+06   \n",
      "1                   39.116506            2.025726e+07   \n",
      "2                   48.948746            3.121025e+07   \n",
      "3                  233.755831            2.438193e+07   \n",
      "4                   74.540641            7.761927e+07   \n",
      "\n",
      "   pessimistic_2100_Change (%)  \n",
      "0                   948.221156  \n",
      "1                    97.488290  \n",
      "2                   102.446830  \n",
      "3                   463.765074  \n",
      "4                   157.293074  \n"
     ]
    }
   ],
   "source": [
    "input_files=[\n",
    "    f'{results_path}tc_admin0_0.55_event-based.csv',\n",
    "    f'{results_path}cf_admin0_0.55_check.csv',\n",
    "    f'{results_path}FL_admin0.csv',\n",
    "    f'{results_path}drought_admin0.csv'\n",
    "]\n",
    "\n",
    "future_years = [2050, 2100]\n",
    "future_scenarios = ['optimistic', 'pessimistic']\n",
    "\n",
    "summary = calculate_future_changes_multiple_scenarios(\n",
    "    input_files=input_files,\n",
    "    baseline_year=2020,\n",
    "    baseline_scenario='current',\n",
    "    future_years=future_years,\n",
    "    future_scenarios=future_scenarios,\n",
    "    metric='AAD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(f'{results_path}global_summaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values referred to in the results section at various occasions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_per_capita_ranking_table(input_files, population_files, year, scenario, metric):\n",
    "    \"\"\"\n",
    "    Create a table ranking countries independently for each hazard, using per capita values.\n",
    "    \n",
    "    Args:\n",
    "    - input_files: List of CSV file paths, one for each hazard.\n",
    "    - population_files: List of CSV file paths, one for each hazard's population data.\n",
    "    - year: Time period to filter (e.g., 2020, 2050, 2100).\n",
    "    - scenario: Scenario to filter (e.g., 'current', 'optimistic', 'pessimistic').\n",
    "    - metric: Metric to rank by (e.g., 'AAD').\n",
    "    - output_file: Path to save the resulting table as a CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Table with independent rankings for each hazard based on per capita values.\n",
    "    \"\"\"\n",
    "    ranking_data = []\n",
    "    hazard_names = []\n",
    "    output_file=f'{results_path}per_capita_ranking_table_{year}_{scenario}_{metric}.csv'\n",
    "\n",
    "    for csv_file, pop_file in zip(input_files, population_files):\n",
    "        # Extract hazard name from file name\n",
    "        hazard_name = csv_file.split(\"/\")[-1].split(\".\")[0]  # Use file name as hazard name\n",
    "        hazard_names.append(hazard_name)\n",
    "        \n",
    "        # Load population data specific to this hazard\n",
    "        pop_df = pd.read_csv(pop_file)\n",
    "\n",
    "        # Load and filter data\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df.merge(pop_df, on='admin0', how='left')\n",
    "        df['per_capita'] = df[metric] / df['valhum']\n",
    "        df_filtered = df[(df['year'] == year) & (df['scenario'] == scenario)]\n",
    "        \n",
    "        # Rank countries by per capita value for the current hazard\n",
    "        df_ranked = df_filtered[['admin0', 'per_capita']].sort_values(by='per_capita', ascending=False).reset_index(drop=True)\n",
    "        df_ranked['Rank'] = df_ranked.index + 1\n",
    "        \n",
    "        # Append hazard-specific ranking data\n",
    "        ranking_data.append(df_ranked[['Rank', 'admin0', 'per_capita']].rename(\n",
    "            columns={'admin0': f'{hazard_name}_Country', 'per_capita': f'{hazard_name}_Per_Capita'}\n",
    "        ))\n",
    "\n",
    "    # Combine all rankings into a single table\n",
    "    result = pd.concat(ranking_data, axis=1)\n",
    "    \n",
    "    # Keep only the first Rank column\n",
    "    rank_column = result['Rank'].iloc[:, 0]\n",
    "    result = result.drop(columns=[col for col in result.columns if col == 'Rank'])\n",
    "    result.insert(0, 'Rank', rank_column)\n",
    "\n",
    "    # Save the full ordered table to a CSV file\n",
    "    result.to_csv(output_file, index=False)\n",
    "\n",
    "    # Display only the top 10 rows\n",
    "    top10 = result.head(10)\n",
    "    print(top10)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hazard_ranking_table(input_files, year, scenario, metric):\n",
    "    \"\"\"\n",
    "    Create a table ranking countries independently for each hazard, with a single rank column.\n",
    "    \n",
    "    Args:\n",
    "    - input_files: List of CSV file paths, one for each hazard.\n",
    "    - year: Time period to filter (e.g., 2020, 2050, 2100).\n",
    "    - scenario: Scenario to filter (e.g., 'current', 'optimistic', 'pessimistic').\n",
    "    - metric: Metric to rank by (e.g., 'AAD').\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Table with independent rankings for each hazard and a single Rank column.\n",
    "    \"\"\"\n",
    "    ranking_data = []\n",
    "    hazard_names = []\n",
    "    output_file=f'{results_path}hazard_ranking_table_{year}_{scenario}_{metric}.csv'\n",
    "\n",
    "    for csv_file in input_files:\n",
    "        # Extract hazard name from file name\n",
    "        hazard_name = csv_file.split(\"/\")[-1].split(\".\")[0]  # Use file name as hazard name\n",
    "        hazard_names.append(hazard_name)\n",
    "        \n",
    "        # Load and filter data\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df_filtered = df[(df['year'] == year) & (df['scenario'] == scenario)]\n",
    "        \n",
    "        # Rank countries by displacement for the current hazard\n",
    "        df_ranked = df_filtered[['admin0', metric]].sort_values(by=metric, ascending=False).reset_index(drop=True)\n",
    "        df_ranked['Rank'] = df_ranked.index + 1\n",
    "        \n",
    "        # Append hazard-specific ranking data\n",
    "        ranking_data.append(df_ranked[['Rank', 'admin0', metric]].rename(\n",
    "            columns={'admin0': f'{hazard_name}_Country', metric: f'{hazard_name}_Displacement'}\n",
    "        ))\n",
    "\n",
    "    # Combine all rankings into a single table\n",
    "    result = pd.concat(ranking_data, axis=1)\n",
    "    \n",
    "    # Keep only the first Rank column\n",
    "    rank_column = result['Rank'].iloc[:, 0]\n",
    "    result = result.drop(columns=[col for col in result.columns if col == 'Rank'])\n",
    "    result.insert(0, 'Rank', rank_column)\n",
    "\n",
    "    # Save the full ordered table to a CSV file\n",
    "    result.to_csv(output_file, index=False)\n",
    "\n",
    "    # Display only the top 10 rows\n",
    "    top10 = result.head(10)\n",
    "    print(top10)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_future_change_ranking_table(input_files, baseline_year, baseline_scenario, future_year, future_scenario, metric):\n",
    "    \"\"\"\n",
    "    Create a table ranking countries independently for each hazard, based on future changes.\n",
    "    \n",
    "    Args:\n",
    "    - input_files: List of CSV file paths, one for each hazard.\n",
    "    - baseline_year: Year for the baseline scenario (e.g., 2020).\n",
    "    - baseline_scenario: Scenario for the baseline (e.g., 'current').\n",
    "    - future_year: Year for the future scenario (e.g., 2050).\n",
    "    - future_scenario: Scenario for the future (e.g., 'optimistic').\n",
    "    - metric: Metric to calculate relative change (e.g., 'AAD').\n",
    "    - output_file: Path to save the resulting table as a CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Table with independent rankings for each hazard based on future changes.\n",
    "    \"\"\"\n",
    "    ranking_data = []\n",
    "    hazard_names = []\n",
    "    output_file=f'{results_path}future_change_ranking_table_{future_year}_{future_scenario}_{metric}.csv'\n",
    "    \n",
    "    for csv_file in input_files:\n",
    "        # Extract hazard name from file name\n",
    "        hazard_name = csv_file.split(\"/\")[-1].split(\".\")[0]  # Use file name as hazard name\n",
    "        hazard_names.append(hazard_name)\n",
    "        \n",
    "        # Load and filter data\n",
    "        df = pd.read_csv(csv_file)\n",
    "        baseline_data = df[(df['year'] == baseline_year) & (df['scenario'] == baseline_scenario)]\n",
    "        future_data = df[(df['year'] == future_year) & (df['scenario'] == future_scenario)]\n",
    "        \n",
    "        # Merge baseline and future data\n",
    "        merged = pd.merge(\n",
    "            baseline_data[['admin0', metric]],\n",
    "            future_data[['admin0', metric]],\n",
    "            on='admin0',\n",
    "            suffixes=('_baseline', '_future')\n",
    "        )\n",
    "        \n",
    "        # Calculate relative change\n",
    "        merged['relative_change'] = (merged[f'{metric}_future'] - merged[f'{metric}_baseline']) / merged[f'{metric}_baseline'] * 100\n",
    "        merged['relative_change'] = merged['relative_change'].replace([float('inf'), -float('inf')], np.nan)\n",
    "\n",
    "        # Rank countries by relative change\n",
    "        df_ranked = merged[['admin0', 'relative_change']].sort_values(by='relative_change', ascending=False).reset_index(drop=True)\n",
    "        df_ranked['Rank'] = df_ranked.index + 1\n",
    "        \n",
    "        # Append hazard-specific ranking data\n",
    "        ranking_data.append(df_ranked[['Rank', 'admin0', 'relative_change']].rename(\n",
    "            columns={'admin0': f'{hazard_name}_Country', 'relative_change': f'{hazard_name}_Change (%)'}\n",
    "        ))\n",
    "\n",
    "    # Combine all rankings into a single table\n",
    "    result = pd.concat(ranking_data, axis=1)\n",
    "    \n",
    "    # Keep only the first Rank column\n",
    "    rank_column = result['Rank'].iloc[:, 0]\n",
    "    result = result.drop(columns=[col for col in result.columns if col == 'Rank'])\n",
    "    result.insert(0, 'Rank', rank_column)\n",
    "\n",
    "    # Save the full ordered table to a CSV file\n",
    "    result.to_csv(output_file, index=False)\n",
    "\n",
    "    # Display only the top 10 rows\n",
    "    top10 = result.head(10)\n",
    "    print(top10)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank tc_admin0_0_Country  tc_admin0_0_Displacement cf_admin0_0_Country  \\\n",
      "0     1                 PHL             104316.771399                 NLD   \n",
      "1     2                 USA              28671.968123                 BGD   \n",
      "2     3                 CHN               7300.799813                 USA   \n",
      "3     4                 VNM               5535.861263                 CHN   \n",
      "4     5                 THA               5079.057371                 EGY   \n",
      "5     6                 IND               2995.845246                 JPN   \n",
      "6     7                 TZA               2637.480909                 IND   \n",
      "7     8                 HTI               2579.378834                 PHL   \n",
      "8     9                 MOZ               1323.504145                 ITA   \n",
      "9    10                 CUB                894.972221                 CAN   \n",
      "\n",
      "   cf_admin0_0_Displacement FL_admin0_Country  FL_admin0_Displacement  \\\n",
      "0              7.326491e+06               VNM            2.643728e+06   \n",
      "1              7.776054e+05               IND            2.384123e+06   \n",
      "2              5.873391e+05               CHN            1.987505e+06   \n",
      "3              3.933831e+05               PAK            9.981452e+05   \n",
      "4              2.810037e+05               BGD            7.403624e+05   \n",
      "5              2.617767e+05               MMR            5.534891e+05   \n",
      "6              1.519823e+05               NGA            5.430379e+05   \n",
      "7              1.264101e+05               KHM            4.768008e+05   \n",
      "8              7.596095e+04               IDN            4.767472e+05   \n",
      "9              6.075226e+04               BRA            4.469367e+05   \n",
      "\n",
      "  drought_admin0_Country  drought_admin0_Displacement  \n",
      "0                    NGA                   628162.109  \n",
      "1                    ETH                   393310.086  \n",
      "2                    PAK                   291030.152  \n",
      "3                    COD                   277221.149  \n",
      "4                    NER                   240095.377  \n",
      "5                    SDN                   188906.904  \n",
      "6                    UGA                   182753.175  \n",
      "7                    MOZ                   163252.287  \n",
      "8                    TZA                   160872.138  \n",
      "9                    SSD                   156336.916  \n"
     ]
    }
   ],
   "source": [
    "ranking_table = create_hazard_ranking_table(\n",
    "    input_files=[\n",
    "        f'{results_path}tc_admin0_0.55_event-based.csv',\n",
    "        f'{results_path}cf_admin0_0.55_check.csv',\n",
    "        f'{results_path}FL_admin0.csv',\n",
    "        f'{results_path}drought_admin0.csv'\n",
    "    ],\n",
    "    year=2020,\n",
    "    scenario='current',\n",
    "    metric='AAD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank tc_admin0_0_Country  tc_admin0_0_Per_Capita cf_admin0_0_Country  \\\n",
      "0     1                 PHL                0.014890                 NLD   \n",
      "1     2                 USA                0.000885                 BGD   \n",
      "2     3                 VNM                0.000652                 DEU   \n",
      "3     4                 SLB                0.000533                 PHL   \n",
      "4     5                 THA                0.000272                 USA   \n",
      "5     6                 TZA                0.000237                 JPN   \n",
      "6     7                 MOZ                0.000199                 EGY   \n",
      "7     8                 MDG                0.000167                 LVA   \n",
      "8     9                 MEX                0.000033                 BEL   \n",
      "9    10                 AUS                0.000028                 CAN   \n",
      "\n",
      "   cf_admin0_0_Per_Capita FL_admin0_Country  FL_admin0_Per_Capita  \\\n",
      "0                0.222842               KHM              0.042998   \n",
      "1                0.039750               LAO              0.038183   \n",
      "2                0.002870               VNM              0.031106   \n",
      "3                0.002662               MLI              0.027598   \n",
      "4                0.002443               BGD              0.024494   \n",
      "5                0.002290               SDN              0.024468   \n",
      "6                0.001688               GMB              0.024250   \n",
      "7                0.001316               ROU              0.023999   \n",
      "8                0.001249               GAB              0.020624   \n",
      "9                0.001114               MDG              0.020543   \n",
      "\n",
      "  drought_admin0_Country  drought_admin0_Per_Capita  \n",
      "0                    SSD                   0.472496  \n",
      "1                    NER                   0.433514  \n",
      "2                    MLI                   0.433080  \n",
      "3                    ZWE                   0.362479  \n",
      "4                    GNB                   0.329521  \n",
      "5                    BDI                   0.325732  \n",
      "6                    SOM                   0.314847  \n",
      "7                    MOZ                   0.311208  \n",
      "8                    CAF                   0.304606  \n",
      "9                    SDN                   0.300225  \n"
     ]
    }
   ],
   "source": [
    "per_capita_table = create_per_capita_ranking_table(\n",
    "    input_files=[\n",
    "        f'{results_path}tc_admin0_0.55_event-based.csv',\n",
    "        f'{results_path}cf_admin0_0.55_check.csv',\n",
    "        f'{results_path}FL_admin0.csv',\n",
    "        f'{results_path}drought_admin0.csv'\n",
    "    ],\n",
    "    population_files = [\n",
    "        f'{results_path}pop_count_admin0.csv',\n",
    "        f'{results_path}pop_count_admin0.csv',\n",
    "        f'{results_path}pop_count_admin0.csv',\n",
    "        f'{results_path}pop_count_admin0_drought.csv'\n",
    "    ],\n",
    "    year=2020,\n",
    "    scenario='current',\n",
    "    metric='PMD_100'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank tc_admin0_0_Country  tc_admin0_0_Change (%) cf_admin0_0_Country  \\\n",
      "0     1                 MDV            9.153166e+07                 SUR   \n",
      "1     2                 WSM            2.140673e+05                 MRT   \n",
      "2     3                 BHS            4.298425e+04                 THA   \n",
      "3     4                 CAN            1.861781e+04                 SLE   \n",
      "4     5                 TWN            1.258860e+04                 GTM   \n",
      "5     6                 MYS            4.276025e+03                 JAM   \n",
      "6     7                 MAC            1.875961e+03                 KHM   \n",
      "7     8                 KHM            1.626701e+03                 MAR   \n",
      "8     9                 LKA            1.463067e+03                 ZAF   \n",
      "9    10                 TLS            1.187245e+03                 PER   \n",
      "\n",
      "   cf_admin0_0_Change (%) FL_admin0_Country  FL_admin0_Change (%)  \\\n",
      "0           746812.904652               ITA            512.742293   \n",
      "1           369819.989105               SSD            483.383277   \n",
      "2           363554.428972               AZE            415.912853   \n",
      "3            64595.411489               EGY            399.234001   \n",
      "4             7467.419162               NAM            308.046185   \n",
      "5             7070.922317               SUR            283.711400   \n",
      "6             6381.467336               TLS            260.597433   \n",
      "7             6285.399369               UGA            255.210761   \n",
      "8             5382.498768               DZA            235.317016   \n",
      "9             5227.457695               KEN            175.523985   \n",
      "\n",
      "  drought_admin0_Country  drought_admin0_Change (%)  \n",
      "0                    QAT                2003.268271  \n",
      "1                    ARE                1724.399153  \n",
      "2                    KWT                1661.331713  \n",
      "3                    CYP                1625.888717  \n",
      "4                    OMN                1453.334465  \n",
      "5                    PSE                1381.471805  \n",
      "6                    UZB                1381.405337  \n",
      "7                    SYR                1380.080556  \n",
      "8                    JOR                1282.727017  \n",
      "9                    TKM                1200.186891  \n"
     ]
    }
   ],
   "source": [
    "future_change_table = create_future_change_ranking_table(\n",
    "    input_files=[\n",
    "        f'{results_path}tc_admin0_0.55_event-based.csv',\n",
    "        f'{results_path}cf_admin0_0.55_check.csv',\n",
    "        f'{results_path}FL_admin0.csv',\n",
    "        f'{results_path}drought_admin0.csv'\n",
    "    ],\n",
    "    baseline_year=2020,\n",
    "    baseline_scenario='current',\n",
    "    future_year=2100,\n",
    "    future_scenario='optimistic',\n",
    "    metric='AAD'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climada_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
